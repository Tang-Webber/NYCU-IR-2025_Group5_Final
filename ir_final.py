# -*- coding: utf-8 -*-
"""IR_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lIcY-yidgWlBNqjeL1ppvtwuETGhnxiv
"""

import os
import time
import pickle
import random
import warnings
import numpy as np
import pandas as pd
import torch
import clip
import faiss
from PIL import Image
from pathlib import Path
from tqdm import tqdm
from typing import List, Dict, Optional
from collections import Counter
from geopy.distance import geodesic
from geopy.geocoders import Nominatim
from google import genai

warnings.filterwarnings('ignore')

# ============================================================================
# 1. Configuration
# ============================================================================

CONFIG = {
    "GEMINI_API_KEY": "AI****************************",
    "MODEL_NAME": "gemini-2.0-flash-exp",
    "DATASET_PATH": "./geolocation-geoguessr-images-50k",
    "INDEX_DIR": "./geo_indexes",
    "CLIP_MODEL": "ViT-B/32",
    "DEVICE": "cuda" if torch.cuda.is_available() else "cpu",
    "SEED": 23,
    "TEST_SAMPLE_SIZE": 50,
    "RETRY_DELAY": 20,
    "MAX_RETRIES": 3,

    "RUN_GEMINI_ONLY": True,
    "RUN_KNN": True,
    "RUN_RAG": True,

    "RAG_SAMPLES_PER_K": {
        1: 50,
        3: 50,
        5: 50,
        10: 50
    }
}

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seed(CONFIG['SEED'])
print(f"‚úì Device: {CONFIG['DEVICE']}")

# ============================================================================
# 2. Data Loading
# ============================================================================

def load_dataset_with_coords(root_path: str) -> List[Dict]:
    """ËºâÂÖ•Ë≥áÊñôÈõÜ"""
    print(f"Loading dataset from {root_path}...")
    root = Path(root_path)
    all_data = []

    geolocator = Nominatim(user_agent="geo_rag_research")
    country_cache = {}

    countries = [d for d in root.iterdir() if d.is_dir() and not d.name.startswith('.')]

    for country_dir in tqdm(countries, desc="Scanning folders"):
        country_name = country_dir.name

        if country_name not in country_cache:
            try:
                time.sleep(1)
                loc = geolocator.geocode(country_name, timeout=5)
                country_cache[country_name] = (loc.latitude, loc.longitude) if loc else (0, 0)
            except:
                country_cache[country_name] = (0, 0)

        lat, lon = country_cache[country_name]

        for img_path in list(country_dir.glob("*.[jJ][pP]*[gG]"))[:100]:
            all_data.append({
                "image_path": str(img_path),
                "country": country_name,
                "latitude": lat,
                "longitude": lon
            })

    print(f"‚úì Total images: {len(all_data)}")
    return all_data

# ËºâÂÖ•ËàáÂàÜÂâ≤
full_data = load_dataset_with_coords(CONFIG["DATASET_PATH"])

from sklearn.model_selection import train_test_split
kb_data, test_data = train_test_split(full_data, test_size=0.1, random_state=CONFIG['SEED'])
test_data = test_data[:CONFIG["TEST_SAMPLE_SIZE"]]

print(f"Knowledge Base: {len(kb_data)}, Test Set: {len(test_data)}")

# ============================================================================
# 3. Check GeoCLIP Availability
# ============================================================================

try:
    from geoclip import GeoCLIP
    GEOCLIP_AVAILABLE = True
    print("‚úì GeoCLIP available")
except ImportError:
    GEOCLIP_AVAILABLE = False
    print("‚ö† GeoCLIP not installed")

# ============================================================================
# 4. Unified Engine
# ============================================================================

class UnifiedGeoRAG:
    def __init__(self, encoder_type="CLIP"):
        self.device = CONFIG["DEVICE"]
        self.encoder_type = encoder_type
        self.index = None
        self.knowledge_base = []

        # Initialize Gemini
        self.client = genai.Client(api_key=CONFIG["GEMINI_API_KEY"])

        # Initialize Encoder
        self._load_encoder()

    def _load_encoder(self):
        print(f"‚úì Loading encoder: {self.encoder_type}...")

        if self.encoder_type == "CLIP":
            self.model, self.preprocess = clip.load(CONFIG["CLIP_MODEL"], device=self.device)
            self.model.eval()

        elif self.encoder_type == "GeoCLIP" and GEOCLIP_AVAILABLE:
            self.model = GeoCLIP().to(self.device)
            self.model.eval()

            # GeoCLIP preprocessing
            from torchvision import transforms
            self.preprocess = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(
                    mean=[0.48145466, 0.4578275, 0.40821073],
                    std=[0.26862954, 0.26130258, 0.27577711]
                )
            ])
        else:
            raise ValueError(f"Unknown or unavailable encoder: {self.encoder_type}")

    def encode_image(self, image_path):
        """Áµ±‰∏ÄÁöÑÂúñÂÉèÁ∑®Á¢º‰ªãÈù¢"""
        image = Image.open(image_path).convert("RGB")
        image_input = self.preprocess(image).unsqueeze(0).to(self.device)

        with torch.no_grad():
            if self.encoder_type == "CLIP":
                features = self.model.encode_image(image_input)
            elif self.encoder_type == "GeoCLIP":
                features = self.model.image_encoder(image_input)

        return features.cpu().numpy().flatten().astype('float32')

    def build_index(self, data_list, batch_size=32):
        print(f"Building FAISS index for {self.encoder_type}...")
        embeddings = []
        valid_data = []

        for i in tqdm(range(0, len(data_list), batch_size), desc="Encoding"):
            batch = data_list[i:i+batch_size]
            for item in batch:
                try:
                    emb = self.encode_image(item['image_path'])
                    embeddings.append(emb)
                    valid_data.append(item)
                except Exception as e:
                    continue

        embeddings = np.vstack(embeddings)
        self.index = faiss.IndexFlatL2(embeddings.shape[1])
        self.index.add(embeddings)
        self.knowledge_base = valid_data
        print(f"‚úì Index built. Vectors: {self.index.ntotal}")

    def retrieve(self, query_img_path, k=10):
        """Ê™¢Á¥¢ Top-K Áõ∏‰ººÂúñÂÉè"""
        query_vec = self.encode_image(query_img_path).reshape(1, -1)
        distances, indices = self.index.search(query_vec, k)

        results = []
        for dist, idx in zip(distances[0], indices[0]):
            item = self.knowledge_base[idx].copy()
            item['distance'] = float(dist)
            results.append(item)
        return results

    def generate_gemini_response(self, prompt, images):
        """ÂëºÂè´ Gemini APIÔºàÂåÖÂê´ÈáçË©¶Ê©üÂà∂Ôºâ"""
        contents = [prompt] + images

        last_exception = None  

        for attempt in range(CONFIG["MAX_RETRIES"]):
            try:
                response = self.client.models.generate_content(
                    model=CONFIG["MODEL_NAME"],
                    contents=contents
                )
                return response.text
            except Exception as e:
                last_exception = e
                error_str = str(e)
                if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                    if attempt == CONFIG["MAX_RETRIES"] - 1:
                        break

                    wait = CONFIG["RETRY_DELAY"] * (2 ** attempt)
                    print(f"\n‚ö† Rate limit (Attempt {attempt+1}/{CONFIG['MAX_RETRIES']}). Waiting {wait}s...")
                    time.sleep(wait)
                else:
                    print(f"\n‚ö† API Error: {e}")
                    raise e

        print(f"\n Failed to generate response after {CONFIG['MAX_RETRIES']} attempts.")
        if last_exception:
            raise last_exception
        else:
            raise RuntimeError("Gemini API generation failed due to unknown reasons.")

# ============================================================================
# 5. Evaluation Logic
# ============================================================================

def parse_coords(text):
    """Âæû LLM ÂõûÊáâËß£ÊûêÁ∂ìÁ∑ØÂ∫¶"""
    result = {'latitude': None, 'longitude': None, 'country': None}
    if not text:
        return result

    for line in text.split('\n'):
        line = line.strip()
        if 'Latitude' in line or 'Á∑ØÂ∫¶' in line:
            try:
                result['latitude'] = float(line.split(':')[-1].strip())
            except:
                pass
        elif 'Longitude' in line or 'Á∂ìÂ∫¶' in line:
            try:
                result['longitude'] = float(line.split(':')[-1].strip())
            except:
                pass
        elif 'Country' in line or 'ÂúãÂÆ∂' in line:
            result['country'] = line.split(':')[-1].strip()

    return result

def calculate_error(pred, truth):
    """Ë®àÁÆóË∑ùÈõ¢Ë™§Â∑Æ (km) ÂíåÂúãÂÆ∂ÂåπÈÖç"""
    if pred['latitude'] is None or truth['latitude'] is None:
        return None, False

    try:
        dist = geodesic(
            (pred['latitude'], pred['longitude']),
            (truth['latitude'], truth['longitude'])
        ).kilometers
    except:
        return None, False

    country_match = (str(pred.get('country', '')).lower() == str(truth['country']).lower())
    return dist, country_match

def run_knn_logic(retrieved_items, k, mode='weighted'):
    """Âü∑Ë°å KNN ÁöÑ Vote Êàñ Weighted Average"""
    subset = retrieved_items[:k]

    if k == 1 or mode == 'nearest':
        return {
            'latitude': subset[0]['latitude'],
            'longitude': subset[0]['longitude'],
            'country': subset[0]['country']
        }

    lats = [x['latitude'] for x in subset]
    lons = [x['longitude'] for x in subset]
    countries = [x['country'] for x in subset]

    if mode == 'vote':
        pred_lat = np.median(lats)
        pred_lon = np.median(lons)
        pred_country = Counter(countries).most_common(1)[0][0]

    elif mode == 'weighted':
        weights = [1.0 / (x['distance'] + 1e-6) for x in subset]
        total_w = sum(weights)
        norm_w = [w / total_w for w in weights]

        pred_lat = np.average(lats, weights=norm_w)
        pred_lon = np.average(lons, weights=norm_w)
        pred_country = Counter(countries).most_common(1)[0][0]

    return {'latitude': pred_lat, 'longitude': pred_lon, 'country': pred_country}

def build_rag_prompt(retrieved_items):
    """Âª∫Êßã RAG Prompt"""
    prompt = """You are a geolocation expert. Based on the similar example images and their locations, predict the location of the query image.

Similar Examples:
"""
    for i, item in enumerate(retrieved_items, 1):
        prompt += f"\nExample {i}:\n"
        prompt += f"  Latitude: {item['latitude']}\n"
        prompt += f"  Longitude: {item['longitude']}\n"
        prompt += f"  Country: {item['country']}\n"

    prompt += """\n\nNow predict the location of the query image.

Output format (strictly follow):
Latitude: [your prediction]
Longitude: [your prediction]
Country: [your prediction]
"""
    return prompt

# ============================================================================
# 6. Main Execution
# ============================================================================

RESULTS = []

def log_result(sample_id, method, encoder, k, aggregation, dist, match):
    """Ë®òÈåÑÂñÆÁ≠ÜÂØ¶È©óÁµêÊûú"""
    RESULTS.append({
        "Sample_ID": sample_id,
        "Method": method,
        "Encoder": encoder,
        "K": k,
        "Aggregation": aggregation,
        "Distance_KM": dist,
        "Country_Match": match
    })

def run_experiments():
    """Âü∑Ë°åÊâÄÊúâÂØ¶È©ó"""

    api_calls = 0
    if CONFIG["RUN_GEMINI_ONLY"]:
        api_calls += len(test_data)
    if CONFIG["RUN_RAG"]:
        rag_calls_per_encoder = sum(CONFIG["RAG_SAMPLES_PER_K"].values())
        num_encoders = 1 + (1 if GEOCLIP_AVAILABLE else 0)
        api_calls += rag_calls_per_encoder * num_encoders

    print("\n" + "="*80)
    print(" Starting Full Experiment Suite")
    print("="*80)
    print(f"Gemini Only: {'‚úì' if CONFIG['RUN_GEMINI_ONLY'] else '‚úó'}")
    print(f"KNN: {'‚úì' if CONFIG['RUN_KNN'] else '‚úó'}")
    print(f"RAG: {'‚úì' if CONFIG['RUN_RAG'] else '‚úó'}")
    print(f"\n  Estimated API calls: {api_calls}")
    print("="*80)

    # === Phase 1: Gemini Only (Baseline) ===
    if CONFIG["RUN_GEMINI_ONLY"]:
        print("\n Phase 1: Gemini Only Baseline")
        print("-"*60)

        temp_system = UnifiedGeoRAG("CLIP")

        for i, sample in enumerate(tqdm(test_data, desc="Gemini Only")):
            prompt = """Predict the geographic location of this image.

Output format (strictly follow):
Latitude: [your prediction]
Longitude: [your prediction]
Country: [your prediction]
"""
            img = Image.open(sample['image_path']).convert("RGB")

            resp_text = temp_system.generate_gemini_response(prompt, [img])
            pred = parse_coords(resp_text)
            dist, match = calculate_error(pred, sample)

            log_result(i, "Gemini Only", "None", 0, "None", dist, match)
            time.sleep(2)

    # === Phase 2 & 3: Encoders (CLIP & GeoCLIP) ===
    encoders_to_test = ["CLIP"]
    if GEOCLIP_AVAILABLE:
        encoders_to_test.append("GeoCLIP")

    for encoder_name in encoders_to_test:
        print(f"\nüìä Testing Encoder: {encoder_name}")
        print("-"*60)

        system = UnifiedGeoRAG(encoder_name)
        system.build_index(kb_data)

        # === KNN Experiments (No API calls) ===
        if CONFIG["RUN_KNN"]:
            print(f"\n  üîπ KNN Experiments ({encoder_name})")

            for i, sample in enumerate(tqdm(test_data, desc=f"{encoder_name} KNN")):
                retrieved = system.retrieve(sample['image_path'], k=10)

                # K=1
                pred = run_knn_logic(retrieved, k=1, mode='nearest')
                dist, match = calculate_error(pred, sample)
                log_result(i, "KNN", encoder_name, 1, "Nearest", dist, match)

                # K=3, 5, 10 (Vote & Weighted)
                for k in [3, 5, 10]:
                    for mode in ['vote', 'weighted']:
                        pred = run_knn_logic(retrieved, k, mode=mode)
                        dist, match = calculate_error(pred, sample)
                        agg_name = "Voting" if mode == 'vote' else "Weighted Avg"
                        log_result(i, "KNN", encoder_name, k, agg_name, dist, match)

        # === RAG Experiments (API calls) ===
        if CONFIG["RUN_RAG"]:
            print(f"\n  üîπ RAG Experiments ({encoder_name})")

            for k_val in [1, 3, 5, 10]:
                num_samples_k = CONFIG["RAG_SAMPLES_PER_K"].get(k_val, 0)
                if num_samples_k == 0:
                    continue

                samples_subset = test_data[:num_samples_k]

                for i, sample in enumerate(tqdm(samples_subset, desc=f"{encoder_name} RAG K={k_val}")):
                    retrieved = system.retrieve(sample['image_path'], k=k_val)
                    prompt = build_rag_prompt(retrieved)

                    ex_imgs = []
                    for item in retrieved:
                        try:
                            ex_imgs.append(Image.open(item['image_path']).convert("RGB"))
                        except:
                            continue

                    query_img = Image.open(sample['image_path']).convert("RGB")

                    resp_text = system.generate_gemini_response(prompt, ex_imgs + [query_img])
                    pred = parse_coords(resp_text)
                    dist, match = calculate_error(pred, sample)

                    log_result(i, "RAG", encoder_name, k_val, "LLM-Reasoning", dist, match)
                    time.sleep(3)

    # === Save Results ===
    df = pd.DataFrame(RESULTS)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = f"full_experiment_results_{timestamp}.csv"
    df.to_csv(filename, index=False, encoding='utf-8-sig')

    print("\n" + "="*80)
    print(f"‚úÖ All experiments completed!")
    print(f"‚úÖ Results saved to: {filename}")
    print("="*80)

    return df

df_results = run_experiments()

# ============================================================================
# 7. Analysis & Summary
# ============================================================================

def print_summary_tables(df):
    """ÁîüÊàêÊëòË¶ÅÂ†±Ë°®"""

    print("\n" + "="*80)
    print("üìä EXPERIMENT SUMMARY")
    print("="*80)

    print("\n1Ô∏è‚É£ Mean Distance Error (km)")
    print("-"*60)
    summary = df.groupby(['Method', 'Encoder', 'K', 'Aggregation'])['Distance_KM'].agg(['mean', 'median', 'count']).reset_index()
    summary = summary.sort_values(by='mean')
    print(summary.to_string(index=False))

    # Accuracy @ Thresholds
    thresholds = [1, 25, 200, 750, 2500]
    print(f"\n2Ô∏è‚É£ Accuracy @ Distance Thresholds")
    print("-"*60)

    for t in thresholds:
        df[f'Acc@{t}km'] = (df['Distance_KM'] <= t).astype(float)

    acc_cols = [f'Acc@{t}km' for t in thresholds]
    acc_summary = df.groupby(['Method', 'Encoder', 'K', 'Aggregation'])[acc_cols + ['Country_Match']].mean() * 100
    print(acc_summary.round(2))

    print(f"\n3Ô∏è‚É£ Top 5 Methods (by Mean Distance)")
    print("-"*60)
    top5 = summary.nsmallest(5, 'mean')
    for idx, row in top5.iterrows():
        print(f"{row['Method']:12} | {row['Encoder']:8} | K={row['K']:2} | {row['Aggregation']:15} | {row['mean']:.2f} km")

if not df_results.empty:
    print_summary_tables(df_results)

# ============================================================================
# 6. Main Execution (Experiment V2: Gemini 2.5)
# ============================================================================

CONFIG["MODEL_NAME"] = "gemini-2.5-flash-image"
print(f"üîÑ [V2] Model switched to: {CONFIG['MODEL_NAME']}")

RESULTS_V2 = []

def log_result_v2(sample_id, method, encoder, k, aggregation, dist, match):
    """Ë®òÈåÑÂñÆÁ≠ÜÂØ¶È©óÁµêÊûú (V2)"""
    RESULTS_V2.append({
        "Sample_ID": sample_id,
        "Method": method,
        "Encoder": encoder,
        "K": k,
        "Aggregation": aggregation,
        "Distance_KM": dist,
        "Country_Match": match,
        "Model_Version": CONFIG["MODEL_NAME"]
    })

def run_experiments_v2():
    """Âü∑Ë°åÊâÄÊúâÂØ¶È©ó (V2)"""

    api_calls = 0
    if CONFIG["RUN_GEMINI_ONLY"]:
        api_calls += len(test_data)
    if CONFIG["RUN_RAG"]:
        rag_calls_per_encoder = sum(CONFIG["RAG_SAMPLES_PER_K"].values())
        num_encoders = 1 + (1 if GEOCLIP_AVAILABLE else 0)
        api_calls += rag_calls_per_encoder * num_encoders

    print("\n" + "="*80)
    print(f" Starting Full Experiment Suite [V2: {CONFIG['MODEL_NAME']}]")
    print("="*80)
    print(f"Gemini Only: {'‚úì' if CONFIG['RUN_GEMINI_ONLY'] else '‚úó'}")
    print(f"KNN: {'‚úì' if CONFIG['RUN_KNN'] else '‚úó'}")
    print(f"RAG: {'‚úì' if CONFIG['RUN_RAG'] else '‚úó'}")
    print(f"\n  Estimated API calls: {api_calls}")
    print("="*80)

    # === Phase 1: Gemini Only (Baseline) ===
    if CONFIG["RUN_GEMINI_ONLY"]:
        print(f"\n Phase 1: Gemini Only Baseline ({CONFIG['MODEL_NAME']})")
        print("-"*60)

        temp_system = UnifiedGeoRAG("CLIP")

        for i, sample in enumerate(tqdm(test_data, desc="Gemini Only")):
            prompt = """Predict the geographic location of this image.

Output format (strictly follow):
Latitude: [your prediction]
Longitude: [your prediction]
Country: [your prediction]
"""
            img = Image.open(sample['image_path']).convert("RGB")

            resp_text = temp_system.generate_gemini_response(prompt, [img])
            pred = parse_coords(resp_text)
            dist, match = calculate_error(pred, sample)

            log_result_v2(i, "Gemini Only", "None", 0, "None", dist, match)
            # time.sleep(1)

    # === Phase 2 & 3: Encoders (CLIP & GeoCLIP) ===
    encoders_to_test = ["CLIP"]
    if GEOCLIP_AVAILABLE:
        encoders_to_test.append("GeoCLIP")

    for encoder_name in encoders_to_test:
        print(f"\n Testing Encoder: {encoder_name}")
        print("-"*60)

        # Âª∫Á´ãÁ¥¢Âºï
        system = UnifiedGeoRAG(encoder_name)
        system.build_index(kb_data)

        # === KNN Experiments (No API calls) ===
        if CONFIG["RUN_KNN"]:
            print(f"\n  üîπ KNN Experiments ({encoder_name})")

            for i, sample in enumerate(tqdm(test_data, desc=f"{encoder_name} KNN")):
                retrieved = system.retrieve(sample['image_path'], k=10)

                # K=1
                pred = run_knn_logic(retrieved, k=1, mode='nearest')
                dist, match = calculate_error(pred, sample)
                log_result_v2(i, "KNN", encoder_name, 1, "Nearest", dist, match)

                # K=3, 5, 10
                for k in [3, 5, 10]:
                    for mode in ['vote', 'weighted']:
                        pred = run_knn_logic(retrieved, k, mode=mode)
                        dist, match = calculate_error(pred, sample)
                        agg_name = "Voting" if mode == 'vote' else "Weighted Avg"
                        log_result_v2(i, "KNN", encoder_name, k, agg_name, dist, match)

        # === RAG Experiments (API calls) ===
        if CONFIG["RUN_RAG"]:
            print(f"\n  üîπ RAG Experiments ({encoder_name}) - Using {CONFIG['MODEL_NAME']}")

            for k_val in [1, 3, 5, 10]:
                num_samples_k = CONFIG["RAG_SAMPLES_PER_K"].get(k_val, 0)
                if num_samples_k == 0:
                    continue

                samples_subset = test_data[:num_samples_k]

                for i, sample in enumerate(tqdm(samples_subset, desc=f"{encoder_name} RAG K={k_val}")):
                    retrieved = system.retrieve(sample['image_path'], k=k_val)
                    prompt = build_rag_prompt(retrieved)

                    ex_imgs = []
                    for item in retrieved:
                        try:
                            ex_imgs.append(Image.open(item['image_path']).convert("RGB"))
                        except:
                            continue

                    query_img = Image.open(sample['image_path']).convert("RGB")

                    resp_text = system.generate_gemini_response(prompt, ex_imgs + [query_img])
                    pred = parse_coords(resp_text)
                    dist, match = calculate_error(pred, sample)

                    log_result_v2(i, "RAG", encoder_name, k_val, "LLM-Reasoning", dist, match)

    # === Save Results V2 ===
    df = pd.DataFrame(RESULTS_V2)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = f"full_experiment_results_GEMINI_2.5_{timestamp}.csv"
    df.to_csv(filename, index=False, encoding='utf-8-sig')

    print("\n" + "="*80)
    print(f"‚úÖ [V2] All experiments completed!")
    print(f"‚úÖ [V2] Results saved to: {filename}")
    print("="*80)

    return df

df_results_v2 = run_experiments_v2()

# ============================================================================
# 7. Analysis & Summary (V2 + Comparison)
# ============================================================================

def print_summary_tables(df, title_suffix=""):
    """ÁîüÊàêÊëòË¶ÅÂ†±Ë°®"""

    print("\n" + "="*80)
    print(f"üìä EXPERIMENT SUMMARY {title_suffix}")
    print("="*80)

    if df.empty:
        print("No data available.")
        return

    # Âü∫Êú¨Áµ±Ë®à
    print("\n1Ô∏è‚É£ Mean Distance Error (km)")
    print("-"*60)
    summary = df.groupby(['Method', 'Encoder', 'K', 'Aggregation'])['Distance_KM'].agg(['mean', 'median', 'count']).reset_index()
    summary = summary.sort_values(by='mean')
    print(summary.to_string(index=False))

    # Accuracy @ Thresholds
    thresholds = [1, 25, 200, 750, 2500]
    print(f"\n2Ô∏è‚É£ Accuracy @ Distance Thresholds")
    print("-"*60)

    df = df.copy()
    for t in thresholds:
        df[f'Acc@{t}km'] = (df['Distance_KM'] <= t).astype(float)

    acc_cols = [f'Acc@{t}km' for t in thresholds]
    acc_summary = df.groupby(['Method', 'Encoder', 'K', 'Aggregation'])[acc_cols + ['Country_Match']].mean() * 100
    print(acc_summary.round(2))

    print(f"\n3Ô∏è‚É£ Top 5 Methods (by Mean Distance)")
    print("-"*60)
    top5 = summary.nsmallest(5, 'mean')
    for idx, row in top5.iterrows():
        print(f"{row['Method']:12} | {row['Encoder']:8} | K={row['K']:2} | {row['Aggregation']:15} | {row['mean']:.2f} km")

if 'df_results_v2' in globals() and not df_results_v2.empty:
    print_summary_tables(df_results_v2, title_suffix="(Gemini 2.5 Flash Image)")
else:
    print("‚ö†Ô∏è df_results_v2 not found. Did you run Cell 6?")

if 'df_results' in globals() and 'df_results_v2' in globals():
    print("\n" + "="*80)
    print("‚öîÔ∏è  MODEL COMPARISON: V1 (1.5 Flash) vs V2 (2.5 Flash Image)")
    print("="*80)

    v1_llm = df_results[df_results['Method'].isin(['RAG', 'Gemini Only'])].copy()
    v2_llm = df_results_v2[df_results_v2['Method'].isin(['RAG', 'Gemini Only'])].copy()

    if not v1_llm.empty and not v2_llm.empty:
        avg_v1 = v1_llm.groupby(['Method', 'Encoder', 'K'])['Distance_KM'].mean().rename("V1_Mean_Dist")
        avg_v2 = v2_llm.groupby(['Method', 'Encoder', 'K'])['Distance_KM'].mean().rename("V2_Mean_Dist")

        comparison = pd.concat([avg_v1, avg_v2], axis=1)
        comparison['Improvement (km)'] = comparison['V1_Mean_Dist'] - comparison['V2_Mean_Dist']
        comparison['Improvement (%)'] = ((comparison['V1_Mean_Dist'] - comparison['V2_Mean_Dist']) / comparison['V1_Mean_Dist']) * 100

        print(comparison.round(2).to_string())
        print("\n(Positive improvement means V2 has lower error distance)")
    else:
        print("Not enough overlapping data to compare LLM performance.")

import matplotlib.pyplot as plt

def run_qualitative_showcase(system, data_source, num_samples=5, k=3):
    """
    Ë≥™ÊÄßÂàÜÊûêÂ±ïÁ§∫Ê®°ÂºèÔºö‰∏çË®àÁÆóË™§Â∑ÆÔºåÂ∞àÊ≥®ÊñºÁîüÊàêÊèèËø∞ÊÄßÊñáÂ≠ó„ÄÇ

    Args:
        system: Â∑≤ÂàùÂßãÂåñÁöÑ UnifiedGeoRAG ÂØ¶‰æã
        data_source: Ê∏¨Ë©¶Ë≥áÊñôÈõÜ (test_data)
        num_samples: Ë¶ÅÂ±ïÁ§∫ÁöÑÊ®£Êú¨Êï∏
        k: RAG Ê™¢Á¥¢ÂºµÊï∏
    """
    print(f"\n{'='*80}")
    print(f"üì∏ Qualitative Showcase (Top {num_samples} samples)")
    print(f"Generating descriptive reports with {system.encoder_type} RAG (K={k})...")
    print(f"{'='*80}\n")

    import random
    selected_samples = random.sample(data_source, num_samples)

    for i, sample in enumerate(selected_samples):
        print(f"\nüîπ Sample {i+1}/{num_samples}")
        print(f"üìç Ground Truth: {sample.get('country', 'Unknown')} ({sample['latitude']:.4f}, {sample['longitude']:.4f})")

        retrieved = system.retrieve(sample['image_path'], k=k)

        prompt = """You are an expert local guide and geographer.
Based on the visual clues in the query image and the retrieved similar locations:

1. **Location Prediction**: Predict the specific location (Latitude, Longitude, Country).
2. **Visual Reasoning**: Briefly explain WHY you think it is this location (e.g., vegetation, road markings, architecture).
3. **Travel Guide**: Write a short, engaging paragraph introducing this location or providing a recommendation for nearby attractions (as if writing for a travel blog).

Similar Examples (Reference):
"""
        for idx, item in enumerate(retrieved, 1):
            prompt += f"  - Ref {idx}: {item['country']} (Lat: {item['latitude']:.2f}, Lon: {item['longitude']:.2f})\n"

        prompt += "\nNow, analyze the query image:"

        ex_imgs = [Image.open(item['image_path']).convert("RGB") for item in retrieved]
        query_img = Image.open(sample['image_path']).convert("RGB")

        try:
            response_text = system.generate_gemini_response(prompt, ex_imgs + [query_img])
        except Exception as e:
            response_text = f"Error generating response: {e}"

        plt.figure(figsize=(12, 6))

        plt.subplot(1, 2, 1)
        plt.imshow(query_img)
        plt.title(f"Query Image\nTrue: {sample.get('country')}")
        plt.axis('off')

        plt.show()

        print(f"üìù **Model Response**:\n{'-'*60}")
        print(response_text)
        print(f"{'-'*60}\n")

        time.sleep(3)

# ==========================================
# Âü∑Ë°åÂ±ïÁ§∫
# ==========================================

system = UnifiedGeoRAG("GeoCLIP")
system.build_index(kb_data)

if 'system' in globals() and system.index is not None:
    run_qualitative_showcase(system, test_data, num_samples=3, k=3)
else:
    print("Á¢∫Ë™ç 'system' ËÆäÊï∏Â≠òÂú®‰∏î Index Â∑≤Âª∫Á´ã„ÄÇ")

